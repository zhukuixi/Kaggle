{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "t938zvkigCml",
        "iLUaQljEhaW4",
        "lXYT8fN9iedH",
        "yQQ6Hbw3khww"
      ],
      "authorship_tag": "ABX9TyP7gj4K0Pekndbj2uBUCZoY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhukuixi/Kaggle/blob/main/HyperParameterTuning_gridsearch_randomsearch_pipeline_optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search\n"
      ],
      "metadata": {
        "id": "t938zvkigCml"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "c9IE2RpWbxX7",
        "outputId": "d72e4d23-0415-495e-f303-e644c8c0ba69"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f090b3251b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sample_data/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"price_range\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/train.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import ensemble\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  df = pd.read_csv(\"/content/sample_data/train.csv\")\n",
        "  X = df.drop(\"price_range\",axis=1).values\n",
        "  y = df.price_range.values\n",
        "\n",
        "  classifier = ensemble.RandomForestClassifier(n_jobs=-1)\n",
        "  param_grid = {\"n_estimators\":[100,200,300,400],\n",
        "          \"max_depth\":[1,3,5,7],\n",
        "          \"criterion\":[\"gini\",\"entropy\"]      \n",
        "          }\n",
        "  model = model_selection.GridSearchCV(\n",
        "      estimator=classifier,\n",
        "      param_grid=param_grid,\n",
        "      scoring=\"accuracy\",\n",
        "      verbose=10,\n",
        "      n_jobs=1,\n",
        "      cv=5\n",
        "  )\n",
        "  model.fit(X,y)\n",
        "  print(model.best_score_)\n",
        "  print(model.best_estimator_.get_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-BzruoSphLTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Search"
      ],
      "metadata": {
        "id": "iLUaQljEhaW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  param_grid = {\"n_estimators\":np.arange(100,1500,100),\n",
        "          \"max_depth\":np.arange(1,20),\n",
        "          \"criterion\":[\"gini\",\"entropy\"]      \n",
        "          }\n",
        "  model = model_selection.RandomizedSearchCV(\n",
        "      estimator=classifier,\n",
        "      n_iter = 10,\n",
        "      param_distributions=param_grid,\n",
        "      scoring=\"accuracy\",\n",
        "      verbose=10,\n",
        "      n_jobs=1,\n",
        "      cv=5\n",
        "  )\n",
        "  model.fit(X,y)\n",
        "  print(model.best_score_)\n",
        "  print(model.best_estimator_.get_params)"
      ],
      "metadata": {
        "id": "CNuIlNBNfGVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Search with pipeline\n",
        "Now you can even tune the hyperparameters in the preprocessing steps involved in the pipeline."
      ],
      "metadata": {
        "id": "lXYT8fN9iedH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import decomposition\n",
        "from sklearn import preprocessing\n",
        "from sklearn import pipeline\n",
        "\n",
        "scl = preprocessing.StandardScaler()\n",
        "pca = decomposition.PCA()\n",
        "rf = ensemble.RandomForestClassifier(n_jobs=-1)\n",
        "\n",
        "classifier = pipeline.Pipeline(\n",
        "    [(\"scaling\",scl),\n",
        "     (\"pca\",pca),\n",
        "     (\"rf\",rf)        \n",
        "    ]\n",
        ")\n",
        "# the name of hyperparameter matches the name you define in pipeline\n",
        "# there are 2 underscore between pca and n_components\n",
        "param_grid = {\"pca__n_components\":np.arange(5,10),            \n",
        "       \"rf__n_estimators\":np.arange(100,1500,100),\n",
        "        \"rf__max_depth\":np.arange(1,20),\n",
        "        \"rf__criterion\":[\"gini\",\"entropy\"]      \n",
        "        }\n",
        "model = model_selection.RandomizedSearchCV(\n",
        "    estimator=classifier,\n",
        "    n_iter=10,\n",
        "    param_distributions=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    verbose=10,\n",
        "    n_jobs=1,\n",
        "    cv=5\n",
        ")\n",
        "model.fit(X,y)\n",
        "print(model.best_score_)\n",
        "print(model.best_estimator_.get_params)"
      ],
      "metadata": {
        "id": "5Xuk9l6bitpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optuna"
      ],
      "metadata": {
        "id": "yQQ6Hbw3khww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import decomposition\n",
        "from sklearn import preprocessing\n",
        "from sklearn import pipeline\n",
        "\n",
        "\n",
        "\n",
        "import optuna"
      ],
      "metadata": {
        "id": "_BpQGnxlN1ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trail,X,y):\n",
        "  #scl = preprocessing.StandardScaler()\n",
        "  #pca = decomposition.PCA(n_components=trail.suggest_int('pca__n_components',5,10))\n",
        "  rf = ensemble.RandomForestClassifier(\n",
        "      n_estimators=trail.suggest_int('rf__n_estimators',100,1500,100),\n",
        "      max_depth = trail.suggest_int('rf__max_depth',1,20),\n",
        "      criterion = trail.suggest_categorical('rf__criterion',[\"gini\",\"entropy\"])\n",
        "  )\n",
        "\n",
        "  kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "  acc_store = []\n",
        "  for idx in kf.split(X,y):\n",
        "    train_idx, test_idx = idx[0],idx[1]\n",
        "    x_train = X[train_idx]\n",
        "    y_train = y[train_idx]\n",
        "\n",
        "    x_test = X[test_idx]\n",
        "    y_test = y[test_idx]\n",
        "   # x_train = scl.fit_transform(x_train)\n",
        "   # x_train = pca.fit_transform(x_train)\n",
        "\n",
        "\n",
        "    rf.fit(x_train,y_train)\n",
        "   # preds = rf.predict(pca.transform(scl.transform(x_test)))\n",
        "    preds = rf.predict(x_test)\n",
        "\n",
        "    acc_store.append(accuracy_score(preds,y_test))\n",
        "  return np.mean(acc_store)\n"
      ],
      "metadata": {
        "id": "7TZIkN-5jp59"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial"
      ],
      "metadata": {
        "id": "fJ2lfe2QRXuH"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/sample_data/train.csv\")\n",
        "X = df.drop(\"price_range\",axis=1).values\n",
        "y = df.price_range.values\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "objective_partial = partial(objective,X=X,y=y)\n",
        "study.optimize(objective_partial, n_trials=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZggbgzxPIAg",
        "outputId": "74f4865d-9f41-4cbf-b880-18f91dfdca76"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-03-23 21:16:55,488]\u001b[0m A new study created in memory with name: no-name-d298c318-312f-4b1c-9e2f-120bdbe3212b\u001b[0m\n",
            "\u001b[32m[I 2023-03-23 21:16:58,775]\u001b[0m Trial 0 finished with value: 0.873 and parameters: {'rf__n_estimators': 100, 'rf__max_depth': 17, 'rf__criterion': 'gini'}. Best is trial 0 with value: 0.873.\u001b[0m\n",
            "\u001b[32m[I 2023-03-23 21:17:39,136]\u001b[0m Trial 1 finished with value: 0.8845000000000001 and parameters: {'rf__n_estimators': 1300, 'rf__max_depth': 20, 'rf__criterion': 'entropy'}. Best is trial 1 with value: 0.8845000000000001.\u001b[0m\n",
            "\u001b[32m[I 2023-03-23 21:18:12,067]\u001b[0m Trial 2 finished with value: 0.8795 and parameters: {'rf__n_estimators': 1200, 'rf__max_depth': 9, 'rf__criterion': 'entropy'}. Best is trial 1 with value: 0.8845000000000001.\u001b[0m\n",
            "\u001b[32m[I 2023-03-23 21:18:14,977]\u001b[0m Trial 3 finished with value: 0.8310000000000001 and parameters: {'rf__n_estimators': 100, 'rf__max_depth': 5, 'rf__criterion': 'entropy'}. Best is trial 1 with value: 0.8845000000000001.\u001b[0m\n",
            "\u001b[32m[I 2023-03-23 21:18:27,382]\u001b[0m Trial 4 finished with value: 0.877 and parameters: {'rf__n_estimators': 500, 'rf__max_depth': 11, 'rf__criterion': 'gini'}. Best is trial 1 with value: 0.8845000000000001.\u001b[0m\n",
            "\u001b[32m[I 2023-03-23 21:18:28,855]\u001b[0m Trial 5 finished with value: 0.54 and parameters: {'rf__n_estimators': 100, 'rf__max_depth': 1, 'rf__criterion': 'entropy'}. Best is trial 1 with value: 0.8845000000000001.\u001b[0m\n",
            "\u001b[32m[I 2023-03-23 21:18:32,269]\u001b[0m Trial 6 finished with value: 0.8154999999999999 and parameters: {'rf__n_estimators': 200, 'rf__max_depth': 4, 'rf__criterion': 'entropy'}. Best is trial 1 with value: 0.8845000000000001.\u001b[0m\n",
            "\u001b[32m[I 2023-03-23 21:18:34,695]\u001b[0m Trial 7 finished with value: 0.7645 and parameters: {'rf__n_estimators': 200, 'rf__max_depth': 2, 'rf__criterion': 'gini'}. Best is trial 1 with value: 0.8845000000000001.\u001b[0m\n",
            "\u001b[32m[I 2023-03-23 21:19:09,515]\u001b[0m Trial 8 finished with value: 0.8860000000000001 and parameters: {'rf__n_estimators': 1100, 'rf__max_depth': 20, 'rf__criterion': 'entropy'}. Best is trial 8 with value: 0.8860000000000001.\u001b[0m\n",
            "\u001b[32m[I 2023-03-23 21:19:14,347]\u001b[0m Trial 9 finished with value: 0.8385 and parameters: {'rf__n_estimators': 300, 'rf__max_depth': 5, 'rf__criterion': 'gini'}. Best is trial 8 with value: 0.8860000000000001.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ra1Wo2Anil7Y"
      }
    }
  ]
}